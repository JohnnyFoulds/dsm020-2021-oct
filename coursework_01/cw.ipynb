{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 1 - This needs a proper title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Background\n",
    "\n",
    "- Why this study is of interest and relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Study Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Motivation and Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Research Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Research Methodology\n",
    "\n",
    "- Describe that the study will be primary a NLP project and this is why the NLP preparation to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Source\n",
    "\n",
    "- Describe why Hellopeter \n",
    "- A good explanation as to why this data source has been selected.\n",
    "- Justify that this is a major source of reviews/complaints which the telecoms actively monitor and respond to. Note that Telkom issued a notice (https://www.hellopeter.com/telkom) that they are phasing it out and urge customers to contact them via twitter opr facebook.\n",
    "- Bellow implement the class to load data from Hellopeter via api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic for retrieving review data from Hellopeter.com is encapsulated in the class below. This allows this class to be moved to a separate .py file to enable re-use and to ensure that activities specifically related to the inner workings of the API have a layer of abstraction should the API change at a future date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hellopeter():\n",
    "    \"\"\"\n",
    "    This class is used to retrieve Hellopeter reviews via the `https://api.hellopeter.com/consumer/business/` API.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    business : str\n",
    "        The business name to retrieve reviews for.\n",
    "    api_url : str\n",
    "        The base URL used to invoke the Hellopeter API.\n",
    "    \"\"\"\n",
    "    def __init__(self, business:str, api_url:str='https://api.hellopeter.com/consumer/business/') -> None:\n",
    "        self.business = business\n",
    "        self.api_url = api_url\n",
    "        self.url_template = self.api_url + self.business + '/reviews?page='\n",
    "\n",
    "        # initialize the session to use for requests to the API\n",
    "        self.request_session = requests.Session()\n",
    "\n",
    "    def request_page(self, page_number:int) -> dict:\n",
    "        \"\"\"\n",
    "        Request a specific review page for the business.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page_number : int\n",
    "            The page number to retrieve the reviews from.   \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            response_json : dict\n",
    "        \"\"\"\n",
    "        # set the full url for the request\n",
    "        url = self.url_template + str(page_number)\n",
    "       \n",
    "        # set the request headers\n",
    "        headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36',\n",
    "            'accept': 'application/json'\n",
    "        }\n",
    "\n",
    "        # request the review page\n",
    "        respose = self.request_session.get(url=url)\n",
    "\n",
    "        # implement basic error handling\n",
    "        if respose.status_code == 202:\n",
    "            return respose.json()\n",
    "        else:\n",
    "            raise Exception('An unexpected response code were received: %s' % respose.status_code)\n",
    "\n",
    "    def process_request_page(self, page_json:dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Process the raw JSON data of a review page and convert it to a Pandas DataFrame.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page_json : dict\n",
    "            The raw JSON (represented as a Python dictionary) that was retrieved from the API.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        page_data : pandas.DataFrame\n",
    "            The page data converted to a DataFrame.            \n",
    "        \"\"\"\n",
    "        # create the dataframe\n",
    "        page_data = pd.DataFrame(page_json['data'])\n",
    "\n",
    "        # add the business name to the dataframe\n",
    "        page_data['business'] = self.business\n",
    "\n",
    "        # basic data type conversions\n",
    "        page_data.created_at = pd.to_datetime(page_data.created_at)\n",
    "        page_data.replied = page_data.replied.astype('bool')        \n",
    "\n",
    "        # return the processed page data\n",
    "        return page_data\n",
    "\n",
    "    def retrieve_reviews(self, stop_at:datetime) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieve reviews for the business up to, and including the `stop_at` date.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stop_at : datetime\n",
    "            The date of the last review to retrieve.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        review_data : pandas.DataFrame\n",
    "            A DataFrame containing the reviews retrieved.            \n",
    "        \"\"\"\n",
    "        page_data = pd.DataFrame()\n",
    "        current_page = 1\n",
    "        stop_retrieval = False\n",
    "\n",
    "        while not stop_retrieval:\n",
    "            # retrieve the reviews for the current page\n",
    "            current_reviews = self.process_request_page(self.request_page(current_page))\n",
    "\n",
    "            # add the current page to the output dataframe\n",
    "            page_data = pd.concat([page_data, current_reviews])\n",
    "\n",
    "            # increment the page counter\n",
    "            current_page += 1\n",
    "\n",
    "            # determine if data retrieval should be stopped\n",
    "            #print(current_reviews.created_at.min(), stop_at)\n",
    "            stop_retrieval = current_reviews.created_at.min() < stop_at\n",
    "\n",
    "            # print a progress indicator\n",
    "            if current_page % 100 == 0:\n",
    "                print(current_page, current_reviews.created_at.min())\n",
    "\n",
    "        # perform the final filter for the stop date\n",
    "        page_data = page_data.query('created_at >= @stop_at')\n",
    "\n",
    "        # return the result dataframe\n",
    "        return page_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_bussiness_reviews(business:str, stop_at:datetime, output_path='data/raw/') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve reviews for a business and store the output in Parquet format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    business : str\n",
    "        The business name to retrieve reviews for.        \n",
    "    stop_at : datetime\n",
    "        The date of the last review to retrieve.    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    review_data : pandas.DataFrame\n",
    "        A DataFrame containing the reviews retrieved.     \n",
    "    \"\"\"\n",
    "    # retrieve the reviews\n",
    "    peter = Hellopeter(business)\n",
    "    review_data = peter.retrieve_reviews(stop_at)\n",
    "\n",
    "    # save the dataset\n",
    "    review_data.to_parquet('data/raw/%s.gzip' % business.replace('-', '_'), \n",
    "        compression='gzip', index=False)\n",
    "\n",
    "    # return the retrieved data for futher processing\n",
    "    return review_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Ethics of Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### C. Data Selection\n",
    "\n",
    " - In this section also describe provider selection (telkom, vodacom, cell c, mtn) and why these major ones only.\n",
    " - in a separate cell use class and save all data to csv\n",
    " - in a separate cell discuss the features that will be selected, then in the next cell drop columns not of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ❗Please do not execute the cells below unless new data is required, retrieving the data is a long running operation. The reviews retrieved on `2021/12/21` can be found in Parquet format on [GitHub](https://github.com/JohnnyFoulds/dsm020-2021-oct/tree/master/coursework_01/data/raw)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2021-11-23 23:32:28\n",
      "200 2021-10-25 13:00:10\n",
      "300 2021-09-26 07:29:06\n",
      "400 2021-08-20 14:14:37\n",
      "500 2021-07-14 19:24:18\n",
      "600 2021-06-10 23:32:14\n",
      "700 2021-05-12 13:09:30\n",
      "800 2021-04-14 11:59:03\n",
      "900 2021-03-18 09:51:51\n",
      "1000 2021-02-24 12:43:47\n",
      "1100 2021-02-03 08:25:32\n",
      "1200 2021-01-11 08:52:58\n"
     ]
    }
   ],
   "source": [
    "# retrieve the vodacom dataset\n",
    "vodacom_reviews = retrieve_bussiness_reviews(business='vodacom', stop_at=datetime.datetime(2021, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2021-11-04 07:36:03\n",
      "200 2021-09-07 19:31:11\n",
      "300 2021-07-19 18:42:15\n",
      "400 2021-05-22 11:36:27\n",
      "500 2021-03-31 18:42:26\n",
      "600 2021-02-17 20:04:42\n",
      "700 2021-01-12 16:14:18\n"
     ]
    }
   ],
   "source": [
    "# retrieve the mtn dataset\n",
    "mtn_reviews = retrieve_bussiness_reviews(business='mtn', stop_at=datetime.datetime(2021, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2021-10-23 20:34:44\n",
      "200 2021-08-24 09:35:28\n",
      "300 2021-06-26 04:53:36\n",
      "400 2021-05-04 23:19:26\n",
      "500 2021-03-15 20:57:52\n",
      "600 2021-02-04 16:39:07\n"
     ]
    }
   ],
   "source": [
    "# retrieve the telkom dataset\n",
    "telkom_reviews = retrieve_bussiness_reviews(business='telkom', stop_at=datetime.datetime(2021, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2021-10-12 14:28:40\n",
      "200 2021-08-12 07:52:06\n",
      "300 2021-06-03 18:50:40\n",
      "400 2021-03-20 14:21:45\n",
      "500 2021-01-21 12:52:35\n"
     ]
    }
   ],
   "source": [
    "# retrieve the cell-c dataset\n",
    "cell_c_reviews = retrieve_bussiness_reviews(business='cell-c', stop_at=datetime.datetime(2021, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ℹ️ Data are loaded from the GitHub repository instead of from the locally saved files. This is under the assumption that this notebook will be submitted as a coursework piece with a size limitation on submission size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the raw datasets retrieved fom hellopeter\n",
    "vodacom_reviews = pd.read_parquet('https://github.com/JohnnyFoulds/dsm020-2021-oct/raw/master/coursework_01/data/raw/vodacom.gzip')\n",
    "mtn_reviews = pd.read_parquet('https://github.com/JohnnyFoulds/dsm020-2021-oct/raw/master/coursework_01/data/raw/mtn.gzip')\n",
    "telkom_reviews = pd.read_parquet('https://github.com/JohnnyFoulds/dsm020-2021-oct/raw/master/coursework_01/data/raw/telkom.gzip')\n",
    "cell_c_reviews = pd.read_parquet('https://github.com/JohnnyFoulds/dsm020-2021-oct/raw/master/coursework_01/data/raw/cell_c.gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sections (a paragraph followed by code) for:\n",
    "\n",
    "- remove empty and illegal values - have clear reasoning described for changes\n",
    "- somehow validate the data, DataFrame.Info maybe as a start, need to think about this\n",
    "- prepare text for NLP analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Limitations\n",
    "\n",
    "- Describe limitations, only hellopeter, but there are many other sources of social media like facebook and twitter. \n",
    "- Predominantly complaints\n",
    "- Specific to telecoms in south africa, similar techniques will be applicable to other industries.\n",
    "- why the dataset is appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Exploratory Data Analysis\n",
    "\n",
    "1. Use Hellopeter to get reviews from 3 cellular providers.\n",
    "2. Clean-up - for example remove empty reviews\n",
    "3. Data Prep\n",
    "4. Analysis\n",
    "\t- Word cloud\n",
    "\t- bar-chart of stars clustered by providers\n",
    "\t- rating counts per month - is the ratings seasonal\n",
    "\t- boxplot of word count for reviews - also interesting correlation between word count and review stars\n",
    "\t- maybe a grid per telecom showing reviews per month vs the number of replies"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
